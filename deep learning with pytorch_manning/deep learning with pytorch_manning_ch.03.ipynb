{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f3f210d",
   "metadata": {},
   "source": [
    "<img src = 'https://images.manning.com/book/3/8e5d003-09e3-430e-a5a3-f42ee1cafb5f/Stevens-DLPy-HI.png' width = '500' height = '770'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0907d59",
   "metadata": {},
   "source": [
    "# 3. It starts with a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28bba8a",
   "metadata": {},
   "source": [
    "The process begins by converting our input into floating-point numbers.\n",
    "\n",
    "In this chapter, we learn how to deal with all the floating-point numbers in PyTorch by using tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39a6007",
   "metadata": {},
   "source": [
    "## 3.1 The world as floating-point numbers\n",
    "\n",
    "We need a way to encode real-world data of the kind we want to process into something digestible by a network\n",
    "\n",
    "and then decode the output back to something we can understand and use for our purpose.\n",
    "\n",
    "Intermediate representations are collections of floating-point numbers that characterize the input\n",
    "\n",
    "and capture the data's structure in a way that is instrumental for describing how inputs are mapped to the outputs of the neural network.\n",
    "\n",
    "These collections of floating-point numbers and their manipulation are at the heart of modern AI.\n",
    "\n",
    "It's important to keep in mind that these intermediate representations are the results of\n",
    "\n",
    "combining the input with the weights of the previous layer of neurons.\n",
    "\n",
    "Each intermediate representation is unique to the inputs that preceeded it.\n",
    "\n",
    "Compared to NumPy arrays, PyTorch tensors have a few superpowers, such as the ability to perform very fast operations on\n",
    "\n",
    "graphical processing units (GPUs), distribute operations on multiple devices or machines,\n",
    "\n",
    "and keep track of the graph of computations that created them.\n",
    "\n",
    "We'll start this chapter by introducing PyTorch tensors, covering the basics in order to set things in motion\n",
    "\n",
    "for our work in the rest of the book."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95977f31",
   "metadata": {},
   "source": [
    "## 3.2 Tensors: Multidimensional arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b236c55",
   "metadata": {},
   "source": [
    "### 3.2.1 From Python lists to PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "449876f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:02:18.806865Z",
     "start_time": "2021-06-29T03:02:18.787883Z"
    }
   },
   "outputs": [],
   "source": [
    "a = [1.0, 2.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40f6e4bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:02:18.976654Z",
     "start_time": "2021-06-29T03:02:18.947701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5215765b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:02:19.132211Z",
     "start_time": "2021-06-29T03:02:19.121240Z"
    }
   },
   "outputs": [],
   "source": [
    "a[2] = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "435f82dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:02:19.336662Z",
     "start_time": "2021-06-29T03:02:19.319708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 2.0, 3.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b8d8e5",
   "metadata": {},
   "source": [
    "As we will see in the following chapter, using the more efficient tensor data structure,\n",
    "\n",
    "many types of data-from images to time series, and even sentences-can be represented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da83bc",
   "metadata": {},
   "source": [
    "### 3.2.2 Constructing our first tensors\n",
    "\n",
    "Let's construct our first PyTorch tensor and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0630b9b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:02:23.251884Z",
     "start_time": "2021-06-29T03:02:20.435420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.ones(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "970739d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:02:23.301749Z",
     "start_time": "2021-06-29T03:02:23.256869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b93009e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:02:23.345632Z",
     "start_time": "2021-06-29T03:02:23.309729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a167be8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:02:23.377547Z",
     "start_time": "2021-06-29T03:02:23.351616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 2.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2] = 2.0\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b19026",
   "metadata": {},
   "source": [
    "Althoug on the surface this example doesn't differ much from a list of number objects,\n",
    "\n",
    "under the hood things are completely different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8395966f",
   "metadata": {},
   "source": [
    "### 3.2.3 The essence of tensors\n",
    "\n",
    "Python lists or tuples of numbers are collections of Python objects that are individually allocated in memory.\n",
    "\n",
    "PyTorch tensors or NumPy arrays, on the other hand, are views over contiguous memory blocks containing unboxed C numeric types rather than Python objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eebf4a80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:02:23.393504Z",
     "start_time": "2021-06-29T03:02:23.381540Z"
    }
   },
   "outputs": [],
   "source": [
    "points = torch.zeros(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75497ff2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:02:23.409461Z",
     "start_time": "2021-06-29T03:02:23.397495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8366fe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:02:23.441376Z",
     "start_time": "2021-06-29T03:02:23.428411Z"
    }
   },
   "outputs": [],
   "source": [
    "points[0] = 4.0\n",
    "points[1] = 1.0\n",
    "points[2] = 5.0\n",
    "points[3] = 3.0\n",
    "points[4] = 2.0\n",
    "points[5] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e303a8",
   "metadata": {},
   "source": [
    "We can also pass a Python list to the constructor, to the same effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91fdad9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:02:23.477280Z",
     "start_time": "2021-06-29T03:02:23.448361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1., 5., 3., 2., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([4.0, 1.0, 5.0, 3.0, 2.0, 1.0])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd4ef75f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:02:23.582003Z",
     "start_time": "2021-06-29T03:02:23.561057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0, 1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(points[0]), float(points[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f3d145f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:02:49.517396Z",
     "start_time": "2021-06-29T03:02:49.491466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2d081d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:02:59.510652Z",
     "start_time": "2021-06-29T03:02:59.500680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cbb7cb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:03:10.153739Z",
     "start_time": "2021-06-29T03:03:10.133789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.zeros(3, 2)\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86874040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:03:34.384549Z",
     "start_time": "2021-06-29T03:03:34.358620Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff117532",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:03:39.921994Z",
     "start_time": "2021-06-29T03:03:39.902049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "699d7410",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:03:46.086580Z",
     "start_time": "2021-06-29T03:03:46.062644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88045b24",
   "metadata": {},
   "source": [
    "## 3.3 Indexing tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fc923d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:05:19.361389Z",
     "start_time": "2021-06-29T03:05:19.347430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list = list(range(6))\n",
    "some_list[1:4:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "611f16ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:05:25.677586Z",
     "start_time": "2021-06-29T03:05:25.658610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1 : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17d4b3c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:05:36.042395Z",
     "start_time": "2021-06-29T03:05:36.014470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 2.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05ebc427",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:05:53.945283Z",
     "start_time": "2021-06-29T03:05:53.931320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 1.],\n",
       "         [5., 3.],\n",
       "         [2., 1.]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267cc4ec",
   "metadata": {},
   "source": [
    "## 3.4 Named tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e702b2d",
   "metadata": {},
   "source": [
    "The dimensions (or axed) of our tensors usually index something like pixel locations or color channels.\n",
    "\n",
    "This means when we want to index into a tensor, we need to remember the ordering of the dimensions and write our indexing accordingly.\n",
    "\n",
    "As data is transformed through multiple tensors, keeping track of which dimension contains what data can be error-prone.\n",
    "\n",
    "To make things concrete, imagine that we have 3D tensor like img_t from section 2.1.4, and we want to convert it to gray-scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8488996e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:08:03.643156Z",
     "start_time": "2021-06-29T03:08:03.623210Z"
    }
   },
   "outputs": [],
   "source": [
    "img_t = torch.randn(3, 5, 5)\n",
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702b709e",
   "metadata": {},
   "source": [
    "We also often want our code to generalize - for example, from grayscale images represented as 2D tensors with height and width dimensions to color images adding a third channel dimension (as in RGB),\n",
    "\n",
    "or from a single image to a batch of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09398396",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:09:09.717881Z",
     "start_time": "2021-06-29T03:09:09.698935Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_t = torch.randn(2, 3, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d13851f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:09:39.169616Z",
     "start_time": "2021-06-29T03:09:39.155654Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), torch.Size([2, 5, 5]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_naive = img_t.mean(-3)\n",
    "batch_gray_naive = batch_t.mean(-3)\n",
    "img_gray_naive.shape, batch_gray_naive.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f2d309",
   "metadata": {},
   "source": [
    "But now we have the weight, too.\n",
    "\n",
    "Pytorch will allow us to multiply things that are the same shape, as well as shape where one operand is of size 1 in a given dimension.\n",
    "\n",
    "It also appends leading dimensions of size 1 automatically.\n",
    "\n",
    "This is a feature called braodcasting.\n",
    "\n",
    "batch_t of shape (2, 3, 5, 5) is multiplied by unsqueezed_weights of shape (3, 1, 1), resulting in a tensor of shape (2, 3, 5, 5),\n",
    "\n",
    "from which we can then sum the third dimnension from the end (the three channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d639e587",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:14:51.484180Z",
     "start_time": "2021-06-29T03:14:51.457251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 5, 5]), torch.Size([2, 3, 5, 5]), torch.Size([3, 1, 1]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze_(-1)\n",
    "img_weights = (img_t * unsqueezed_weights)\n",
    "batch_weights = (batch_t * unsqueezed_weights)\n",
    "img_gray_weighted = img_weights.sum(-3)\n",
    "batch_gray_weighted = batch_weights.sum(-3)\n",
    "batch_weights.shape, batch_t.shape, unsqueezed_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb5340f",
   "metadata": {},
   "source": [
    "Because this gets messy quickly - and for the sake of efficiency - the PyTorch function einsum (adapted from NumPy) specifies an indexing mini-language giving index names to dimensions for sums of such products.\n",
    "\n",
    "As often in Python, broadcasting - a form of summarizing unnamed things - is done three dots '...';\n",
    "\n",
    "but don't worry too much about einsum, becuase we will not use it in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bab1865d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:17:30.579938Z",
     "start_time": "2021-06-29T03:17:30.562984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 5])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_weighted_fancy = torch.einsum('...chw,c->...hw', img_t, weights)\n",
    "batch_gray_weighted_fancy = torch.einsum('...chw,c->...hw', batch_t, weights)\n",
    "batch_gray_weighted_fancy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35759eaf",
   "metadata": {},
   "source": [
    "PyTorch 1.3 added names tensors as an experimental feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6372eca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:18:45.078547Z",
     "start_time": "2021-06-29T03:18:45.056609Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-35865d7e5b1b>:1: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:934.)\n",
      "  weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names = ['channels'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722], names=('channels',))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names = ['channels'])\n",
    "weights_named"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6d8918",
   "metadata": {},
   "source": [
    "When we already have a tensor and want to add names, we can call the method refine_names on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b0b5070",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:20:32.182452Z",
     "start_time": "2021-06-29T03:20:32.172483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img named: torch.Size([3, 5, 5]) ('channels', 'rows', 'columns')\n",
      "batch named: torch.Size([2, 3, 5, 5]) (None, 'channels', 'rows', 'columns')\n"
     ]
    }
   ],
   "source": [
    "img_named = img_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "batch_named = batch_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "print('img named:', img_named.shape, img_named.names)\n",
    "print('batch named:', batch_named.shape, batch_named.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75e4aa5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:23:23.115108Z",
     "start_time": "2021-06-29T03:23:23.099150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1, 1]), ('channels', 'rows', 'columns'))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_aligned = weights_named.align_as(img_named)\n",
    "weights_aligned.shape, weights_aligned.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0580079a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:23:45.273913Z",
     "start_time": "2021-06-29T03:23:45.251968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), ('rows', 'columns'))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_named = (img_named * weights_aligned).sum('channels')\n",
    "gray_named.shape, gray_named.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920e658a",
   "metadata": {},
   "source": [
    "If we try to combine dimensions with different names, we get an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37472ec5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:24:17.561608Z",
     "start_time": "2021-06-29T03:24:17.528695Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error when attempting to broadcast dims ['channels', 'rows', 'columns'] and dims ['channels']: dim 'columns' and dim 'channels' are at the same position from the right but do not match.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-4959ba21081c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgray_named\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimg_named\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mweights_named\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'channels'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Error when attempting to broadcast dims ['channels', 'rows', 'columns'] and dims ['channels']: dim 'columns' and dim 'channels' are at the same position from the right but do not match."
     ]
    }
   ],
   "source": [
    "gray_named = (img_named[..., :3] * weights_named).sum('channels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17bb6741",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:24:49.450672Z",
     "start_time": "2021-06-29T03:24:49.433724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), (None, None))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_plain = gray_named.rename(None)\n",
    "gray_plain.shape, gray_plain.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c760bc0",
   "metadata": {},
   "source": [
    "## 3.5 Tensor element types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9de5a02",
   "metadata": {},
   "source": [
    "Numbers in Python are objects.\n",
    "\n",
    "Lists in Python are meant for sequential collections fo objects.\n",
    "\n",
    "The Python interpreter is slow compared to optimized, compiled code.\n",
    "\n",
    "For these reasons, data science libraries rely on NumPy or introduce dedicated data structures like PyTorch tensors,\n",
    "\n",
    "which provide efficient low-level implementations of numerical data structures and related operations on them, wrapped in a convenient high-level API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778f92a4",
   "metadata": {},
   "source": [
    "### 3.5.1 Specifying the numeric type with dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf3280",
   "metadata": {},
   "source": [
    "### 3.5.2 A dtype for every occasion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7314698",
   "metadata": {},
   "source": [
    "### 3.5.3 Managing a tensor's dtype attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55430baf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:28:44.962618Z",
     "start_time": "2021-06-29T03:28:44.950648Z"
    }
   },
   "outputs": [],
   "source": [
    "double_points = torch.ones(10, 2, dtype = torch.double)\n",
    "short_points = torch.tensor([[1, 2], [3, 4]], dtype = torch.short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27215651",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:28:48.969531Z",
     "start_time": "2021-06-29T03:28:48.958565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int16"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_points.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5fe4c8e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:29:24.963376Z",
     "start_time": "2021-06-29T03:29:24.950412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ccac7e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:29:51.932162Z",
     "start_time": "2021-06-29T03:29:51.923189Z"
    }
   },
   "outputs": [],
   "source": [
    "double_points = torch.zeros(10, 2).double()\n",
    "short_points = torch.ones(10, 2).short()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfbaebc",
   "metadata": {},
   "source": [
    "or the more convenient 'to' method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5cfef190",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:30:40.200559Z",
     "start_time": "2021-06-29T03:30:40.184607Z"
    }
   },
   "outputs": [],
   "source": [
    "double_points = torch.zeros(10, 2).to(torch.double)\n",
    "short_points = torch.ones(10, 2).to(torch.short)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d2db17",
   "metadata": {},
   "source": [
    "When mixing input types in operations, the inputs are converted to the larger type automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d3e1c23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:31:10.757675Z",
     "start_time": "2021-06-29T03:31:10.740722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_64 = torch.rand(5, dtype = torch.double)\n",
    "points_short = points_64.to(torch.short)\n",
    "points_64 * points_short"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf534d5e",
   "metadata": {},
   "source": [
    "## 3.6 The tensor API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c13b1023",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:33:01.887075Z",
     "start_time": "2021-06-29T03:33:01.874109Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3, 2)\n",
    "a_t = torch.transpose(a, 0, 1)\n",
    "\n",
    "a.shape, a_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c007d7c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:33:05.332504Z",
     "start_time": "2021-06-29T03:33:05.311562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c65537",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:34:21.500009Z",
     "start_time": "2021-06-29T03:34:21.478065Z"
    }
   },
   "source": [
    "Creations ops, Math ops, Indexing slicing joining mutating ops, Random sampling, Serialization, Parallelism...\n",
    "\n",
    "Take some time to play with the general tensor API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e060be5",
   "metadata": {},
   "source": [
    "## 3.7 Tensors: Scenic views of storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390f4eaf",
   "metadata": {},
   "source": [
    "### 3.7.1 Indexing into storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e4aa515b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:35:40.139532Z",
     "start_time": "2021-06-29T03:35:40.124573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       "[torch.FloatStorage of size 6]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points.storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dfce32",
   "metadata": {},
   "source": [
    "Even though the tensor reports itself as having three rows and two columns,\n",
    "\n",
    "the storage under the hood is a contiguous array of size 6.\n",
    "\n",
    "We can also index into a storage manually. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "76359079",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:38:57.208658Z",
     "start_time": "2021-06-29T03:38:57.190703Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_storage = points.storage()\n",
    "points_storage[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c4f1e59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:40:02.424297Z",
     "start_time": "2021-06-29T03:40:02.407347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.storage()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45b553a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:40:39.548417Z",
     "start_time": "2021-06-29T03:40:39.538448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points_storage = points.storage()\n",
    "points_storage[0] = 2.0\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb3997",
   "metadata": {},
   "source": [
    "### 3.7.2 Modifying stored values: In-place operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "28ac3c46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:41:04.066877Z",
     "start_time": "2021-06-29T03:41:04.060893Z"
    }
   },
   "outputs": [],
   "source": [
    "a = torch.ones(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "347714d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:41:11.978941Z",
     "start_time": "2021-06-29T03:41:11.967975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.zero_()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654476fa",
   "metadata": {},
   "source": [
    "## 3.8 Tensor metadata: Size, offset, and stride"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d52829",
   "metadata": {},
   "source": [
    "### 3.8.1 Views of another tensor's storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac7c7a55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:42:37.234843Z",
     "start_time": "2021-06-29T03:42:37.220880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_point = points[1]\n",
    "second_point.storage_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "79d5725f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:42:45.586369Z",
     "start_time": "2021-06-29T03:42:45.575397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b09be657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:42:56.312521Z",
     "start_time": "2021-06-29T03:42:56.296594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b216c19d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:43:01.284609Z",
     "start_time": "2021-06-29T03:43:01.275629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9673a225",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:43:15.542851Z",
     "start_time": "2021-06-29T03:43:15.534873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point = points[1]\n",
    "second_point.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "52767989",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:43:26.218950Z",
     "start_time": "2021-06-29T03:43:26.207979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.storage_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7f0f60d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:43:30.035763Z",
     "start_time": "2021-06-29T03:43:30.012796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c0a77507",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:44:00.463739Z",
     "start_time": "2021-06-29T03:44:00.437806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  1.],\n",
       "        [10.,  3.],\n",
       "        [ 2.,  1.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_point = points[1]\n",
    "second_point[0] = 10.0\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d0a90bf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:44:34.500047Z",
     "start_time": "2021-06-29T03:44:34.475085Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_point = points[1].clone()\n",
    "second_point[0] = 10.0\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40525b72",
   "metadata": {},
   "source": [
    "### 3.8.2 Transposing without copying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ab275b68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:45:05.079546Z",
     "start_time": "2021-06-29T03:45:05.067578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ee941713",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:45:14.695002Z",
     "start_time": "2021-06-29T03:45:14.672059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t = points.t()\n",
    "points_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "19282cda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:46:44.157737Z",
     "start_time": "2021-06-29T03:46:44.138788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(points.storage()) == id(points_t.storage)\n",
    "\n",
    "# True 나와야 하는데...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "29d0745a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:46:49.554946Z",
     "start_time": "2021-06-29T03:46:49.533007Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9db479b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:46:54.670308Z",
     "start_time": "2021-06-29T03:46:54.648364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deecc37a",
   "metadata": {},
   "source": [
    "### 3.8.3 Transposing in higher dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5b213ac4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:47:42.237016Z",
     "start_time": "2021-06-29T03:47:42.223051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_t = torch.ones(3, 4, 5)\n",
    "transpose_t = some_t.transpose(0, 2)\n",
    "some_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d99e400d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:47:49.948032Z",
     "start_time": "2021-06-29T03:47:49.927094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 3])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transpose_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "574d334d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:47:56.209381Z",
     "start_time": "2021-06-29T03:47:56.191458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5, 1)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2649e75b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:48:02.689758Z",
     "start_time": "2021-06-29T03:48:02.672804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 20)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transpose_t.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892587c7",
   "metadata": {},
   "source": [
    "### 3.8.4 Contiguous tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "15ea9272",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:48:17.946119Z",
     "start_time": "2021-06-29T03:48:17.934158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1ed1ca71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:48:23.508360Z",
     "start_time": "2021-06-29T03:48:23.495397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3453083d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:48:44.136967Z",
     "start_time": "2021-06-29T03:48:44.115025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points_t = points.t()\n",
    "points_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5bef0b52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:48:48.603950Z",
     "start_time": "2021-06-29T03:48:48.584006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       "[torch.FloatStorage of size 6]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "acd2811b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:48:57.878499Z",
     "start_time": "2021-06-29T03:48:57.865531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3b26545b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:49:08.276828Z",
     "start_time": "2021-06-29T03:49:08.261868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont = points_t.contiguous()\n",
    "points_t_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cd78454e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:49:13.351951Z",
     "start_time": "2021-06-29T03:49:13.337989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "68f4a325",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:49:21.782949Z",
     "start_time": "2021-06-29T03:49:21.771983Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 5.0\n",
       " 2.0\n",
       " 1.0\n",
       " 3.0\n",
       " 1.0\n",
       "[torch.FloatStorage of size 6]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont.storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2dfb9d",
   "metadata": {},
   "source": [
    "## 3.9 Moving tensors to the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0218a12",
   "metadata": {},
   "source": [
    "So far in this chapter, when we've talked about storage, we've meant memory on the CPU.\n",
    "\n",
    "PyTorch tensors also can be stored on a different kind of processor: a graphics processing unit (GPU)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43e6b56",
   "metadata": {},
   "source": [
    "### 3.9.1 Managing a tensor's device attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ccd4d87a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:51:10.166363Z",
     "start_time": "2021-06-29T03:51:10.114501Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-3b6c4702032f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpoints_gpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m5.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\study\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    162\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "62b46eee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:54:47.080132Z",
     "start_time": "2021-06-29T03:54:47.065174Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch와 cuda 버전이 안맞는듯 하다..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc8bcea",
   "metadata": {},
   "source": [
    "## 3.10 NumPy interoperability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dfde2ac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T03:55:19.344569Z",
     "start_time": "2021-06-29T03:55:19.315646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.ones(3, 4)\n",
    "points_np = points.numpy()\n",
    "points_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe5bf83",
   "metadata": {},
   "source": [
    "## 3.11 Generalized tensors are tensors, too"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99374d09",
   "metadata": {},
   "source": [
    "## 3.12 Serializing tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d398c5a6",
   "metadata": {},
   "source": [
    "## 3.13 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea061e2",
   "metadata": {},
   "source": [
    "## 3.14 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a51f589",
   "metadata": {},
   "source": [
    "## 3.15 Summary\n",
    "\n",
    "- Neural networks transform floating-point representations into other floating-point representations. The starting and ending representations are typically human interpretable, but the intermediate representations are less so.\n",
    "\n",
    "- These floating-point representations are stored in tensors.\n",
    "\n",
    "- Tensors are multidimensional arrays; they are the basic data structure in PyTorch.\n",
    "\n",
    "- PyTorch has a comprehensive standard library for tensor creation, manipulation, and mathematical operations.\n",
    "\n",
    "- Tensors can be serialized to disk and loaded back.\n",
    "\n",
    "- All tensor operations in PyTorch can execute on the CPU as well as on the GPU, with no change in the code.\n",
    "\n",
    "- PyTorch uses a trailing underscore to indicate that a function operates in place on a tensor (for example, Tensor.sqrt_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
