{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ce52b51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T04:05:06.274504Z",
     "start_time": "2021-07-09T04:05:06.166757Z"
    }
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb993f2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T04:10:22.049297Z",
     "start_time": "2021-07-09T04:10:14.492273Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
    "  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
    "  pad_token='<pad>', mask_token='<mask>') \n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
    "\n",
    "class Input(BaseModel):\n",
    "    text: str = Field(\n",
    "    title = '문장을 입력해주세요',\n",
    "    max_length = 128\n",
    "    )\n",
    "    max_length: int = Field(\n",
    "    128,\n",
    "    ge = 5,\n",
    "    le = 128\n",
    "    )\n",
    "    repetition_penalty: float = Field(\n",
    "    2.0,\n",
    "    ge = 0.0,\n",
    "    le = 2.0\n",
    "    )\n",
    "        \n",
    "class Output(BaseModel):\n",
    "    generated_text: str\n",
    "        \n",
    "def generate_text(input: Input) -> Output:\n",
    "\n",
    "    input_ids = tokenizer.encode(input.text)\n",
    "    gen_ids = model.generate(torch.tensor([input_ids]),\n",
    "        max_length=input.max_length,\n",
    "        repetition_penalty=input.repetition_penalty,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        bos_token_id=tokenizer.bos_token_id,\n",
    "        use_cache=True)\n",
    "\n",
    "    generated = tokenizer.decode(gen_ids[0,:].tolist())\n",
    "\n",
    "    return Output(generated_text=generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43e07f18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T03:20:13.411627Z",
     "start_time": "2021-07-09T03:20:10.168597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "멘탈이 나갔으면 좋겠다”고 말했다.\n",
      "한편 이날 행사에는 박원순 서울시장, 김황식 국무총리, 이낙연 국무총리 등 정부 주요 인사와 시민, 학생 등이 참석했다.</d> 서울중앙지검 특수1부(부장검사 이원석)는 지난해 11월부터 올 1월까지 전국경제인연합회(전경련) 사무실 등을 압수수색하고 관련자 10여명을 소환조사했다고 2일 밝혔다.\n",
      "검찰은 전경련의 자금관리 담당 임원들을 상대로 회장단 회의록과 회계장부, 컴퓨터 하드디스크를 확보했다.\n",
      "또 회원사들로부터 회삿돈으로 받은 돈의 사용처를 추적하는 한편 전·현직 임직원들의\n"
     ]
    }
   ],
   "source": [
    "text = '멘탈이 나갔으면'\n",
    "input_ids = tokenizer.encode(text)\n",
    "gen_ids = model.generate(torch.tensor([input_ids]),\n",
    "    max_length=128,\n",
    "    repetition_penalty=2.0,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    use_cache=True)\n",
    "\n",
    "generated = tokenizer.decode(gen_ids[0,:].tolist())\n",
    "\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58aa1565",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T03:20:33.547902Z",
     "start_time": "2021-07-09T03:20:30.288055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "언제까지 그렇게 살텐가?\"\n",
      "\"그럼, 그건 내가 알아서 할게요. 아빠는 내일 아침 일찍 일어나서 우리 집에 오셔야 해요! 그리고 오늘은 제가 저녁을 먹으러 갈 거예요, 엄마.\"\n",
      "아이는 울음을 터뜨렸다.\n",
      "엄마는 아이를 안고 집으로 돌아왔다.\n",
      "그리고 엄마가 돌아오기 전에 다시 한 번 아이의 얼굴을 보았다.\n",
      "이제 아이는 눈을 뜨고 있었다.\n",
      "눈물이 핑 돌았다.\n",
      "아이에게 눈물은 없었다.\n",
      "하지만 아이와 함께 있는 시간은 점점 더 길어졌다.\n",
      "어느새 아이가 잠들어 버렸다.\n",
      "나는 이불을 뒤집어쓰고 방문을 열었다.\n",
      "방문이 열리자마자 나는 문 앞에 서서 기다릴\n"
     ]
    }
   ],
   "source": [
    "text = '언제까지 그렇게 살텐가'\n",
    "input_ids = tokenizer.encode(text)\n",
    "gen_ids = model.generate(torch.tensor([input_ids]),\n",
    "    max_length=128,\n",
    "    repetition_penalty=2.0,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    use_cache=True)\n",
    "\n",
    "generated = tokenizer.decode(gen_ids[0,:].tolist())\n",
    "\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebaec1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
